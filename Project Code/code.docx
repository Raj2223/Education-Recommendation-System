
Project Code:

#--------------------Importing Required Libraries/Modules-----------------------#
import pandas as pd
import numpy as np
from sklearn import decomposition
import matplotlib.pyplot as plt

#--------reading the .csv file as input------------#
dataset = pd.read_csv("roo_data.csv") 

#---------Testing by displaying whether data is loaded properly or not-----------#
data = dataset.iloc[:,:-1].values
label = dataset.iloc[:,-1].values
len(data[0])
Dataset.iloc[:,14:38]
Dataset.iloc[:,14:38]

#---------------Applying OneHot & Lable  Encoding-----------#
from sklearn.preprocessing import LabelEncoder, OneHotEncoder
labelencoder = LabelEncoder()
xa=0.813664
#---------------conversion of all categorial column values to vector/numerical--------#
for i in range(14,38):
    data[:,i] = labelencoder.fit_transform(data[:,i])  
data[:5]
Data[:5,14:]

#--------------normalizing the non-categorial column values---------#
from sklearn.preprocessing import Normalizer
data1=data[:,:14]
normalized_data = Normalizer().fit_transform(data1)
print(normalized_data.shape)
da=0.8383
normalized_data
data2=data[:,14:]
data2.shape
df1 = np.append(normalized_data,data2,axis=1)
sa=0.8516
df1.shape


#--------------------------Adding Headers-----------------------#
X1 = pd.DataFrame(df1,columns=['Acedamic percentage in Operating Systems', 'percentage in Algorithms',
       'Percentage in Programming Concepts',
       'Percentage in Software Engineering', 'Percentage in Computer Networks',
       'Percentage in Electronics Subjects',
       'Percentage in Computer Architecture', 'Percentage in Mathematics',
       'Percentage in Communication skills', 'Hours working per day',
       'Logical quotient rating', 'hackathons', 'coding skills rating',
       'public speaking points', 'can work long time before system?',
       'self-learning capability?', 'Extra-courses did', 'certifications',
       'workshops', 'talenttests taken?', 'olympiads',
       'reading and writing skills', 'memory capability score',
       'Interested subjects', 'interested career area ', 'Job/Higher Studies?',
       'Type of company want to settle in?',
       'Taken inputs from seniors or elders', 'interested in games',
       'Interested Type of Books', 'Salary Range Expected',
       'In a Realtionship?', 'Gentle or Tuff behaviour?',
       'Management or Technical', 'Salary/work', 'hard/smart worker',
       'worked in teams ever?', 'Introvert'])
X1.head()

#------------------Encoding Final Output column Values------------#
label = labelencoder.fit_transform(label)
print(len(label))
y=pd.DataFrame(label,columns=["Suggested Job Role"])
y.head()

#------------------Training and testing with Decision Tree----------------#
#------importing modules---------------#
from sklearn import tree
from sklearn.model_selection import train_test_split
from sklearn import preprocessing 
from sklearn.metrics import accuracy_score

#---------------specifying percentage of test data from whole data--------#
X_train,X_test,y_train,y_test=train_test_split(X1,y,test_size=0.2,random_state=10) 

#-----------------classifying with decision tree-----------------------#
clf = tree.DecisionTreeClassifier() 
clf = clf.fit(X_train, y_train)
from sklearn.metrics import confusion_matrix,accuracy_score
y_pred = clf.predict(X_test)
Y_pred

#----------------calculating confusion vector values matrix and accuracy-------------#
cm = confusion_matrix(y_test,y_pred)
accuracy = accuracy_score(y_test,y_pred)
print("confusion matrics=",cm)
print("  ")
print("accuracy=",accuracy*100)

#--------performing decision tree classification with entropy as measure------------#
clf_entropy = tree.DecisionTreeClassifier(criterion = "entropy", random_state = 10)
clf_entropy.fit(X_train, y_train)
entropy_y_pred=clf_entropy.predict(X_test)
cm_entopy = confusion_matrix(y_test,entropy_y_pred)
entropy_accuracy = accuracy_score(y_test,entropy_y_pred)
print("confusion matrics=",cm_entopy)
print("  ")
print("accuracy=",entropy_accuracy*100)

#------classification with svm------------------------#
from sklearn import svm
clf = svm.SVC()
clf.fit(X_train, y_train)   #------giving test data as input----#
svm_y_pred = clf.predict(X_test)   #--------doing prediction-----#

#-----------calculating confusion matrix and accuracy----------#
svm_cm = confusion_matrix(y_test,svm_y_pred)
svm_accuracy = accuracy_score(y_test,svm_y_pred)
print("confusion matrix=",svm_cm)
print("  ")
print("accuracy=",svm_accuracy*100)

#--------------classification using xgboost--------------#
X_train,X_test,y_train,y_test=train_test_split(X1,y,test_size=0.3,random_state=10) 
X_train.shape

#------------converting values of training and testing data into int64 datatype-------#
X_train=pd.to_numeric(X_train.values.flatten())
X_train=X_train.reshape((14000,38))

#-------------importing and defining xgboost functions-----#
from xgboost import XGBClassifier
model = XGBClassifier()
#-----------training and testing with xg boost------#
model.fit(X_train, y_train)
xgb_y_pred = clf.predict(X_test)

#-----calculating confusion matrix and accuracy after boosting--------#
xgb_cm = confusion_matrix(y_test,xgb_y_pred)
xgb_accuracy = accuracy_score(y_test,xgb_y_pred)
print("confusion matrix=",xgb_cm)
print("  ")
print("accuracy=",xgb_accuracy*100)

